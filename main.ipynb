{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import eng_to_ipa as ipa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import  Sequential, Model\n",
    "from tensorflow.keras.layers import Layer, Concatenate, Input, Masking, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data (data file already created in data_import.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfile = open('words.txt','r')\\nlines = file.readlines()\\nfile.close()\\n\\nfile = open('data.csv','w')\\n\\nfile.write('word,pronunciation\\n')\\nfor word in lines:\\n    if ipa.isin_cmu(word):\\n        line = word.strip('\\n') + ',' + ipa.convert(word) + '\\n'\\n        file.write(line)\\n\\nfile.close()\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "file = open('words.txt','r')\n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "\n",
    "file = open('data.csv','w')\n",
    "\n",
    "file.write('word,pronunciation\\n')\n",
    "for word in lines:\n",
    "    if ipa.isin_cmu(word):\n",
    "        line = word.strip('\\n') + ',' + ipa.convert(word) + '\\n'\n",
    "        file.write(line)\n",
    "\n",
    "file.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of initial data: 40315\n",
      "Train size: 32253\n",
      "Val size: 4031\n",
      "Test size: 4031\n",
      "\n",
      "38\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4031, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv ('data.csv',delimiter=',')\n",
    "\n",
    "df.word = df.word.astype(str) \n",
    "df.pronunciation = df.pronunciation.astype(str) \n",
    "\n",
    "#df.applymap(lambda s: s.replace(s,' '.join(str(s))))\n",
    "df['word'] = df['word'].str.replace('',' ')\n",
    "df['pronunciation'] = df['pronunciation'].str.replace('',' ')\n",
    "\n",
    "MAX_NUM_WORDS = 40000\n",
    "\n",
    "# 10% for val, 10% for test, 70% for train\n",
    "val_size = int(df.shape[0] * 0.1)\n",
    "test_size = int(df.shape[0] * 0.1)\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1)\n",
    "# Split df to test/val/train\n",
    "test_df = df[:test_size]\n",
    "val_df = df[test_size:test_size+val_size]\n",
    "train_df = df[test_size+val_size:]\n",
    "\n",
    "\n",
    "train_words, train_pronounciations = list(train_df.word), list(train_df.pronunciation)\n",
    "val_words, val_pronounciations     = list(val_df.word), list(val_df.pronunciation)\n",
    "test_words, test_pronounciations   = list(test_df.word), list(test_df.pronunciation)\n",
    "\n",
    "\n",
    "# Check that idces do not overlap\n",
    "assert set(train_df.index).intersection(set(val_df.index)) == set({})\n",
    "assert set(test_df.index).intersection(set(train_df.index)) == set({})\n",
    "assert set(val_df.index).intersection(set(test_df.index)) == set({})\n",
    "# Check that all idces are present\n",
    "assert df.shape[0] == len(train_pronounciations) + len(val_pronounciations) + len(test_pronounciations)\n",
    "\n",
    "# Sizes\n",
    "print(\n",
    "    f\"Size of initial data: {df.shape[0]}\\n\"\n",
    "    f\"Train size: {len(train_pronounciations)}\\n\"\n",
    "    f\"Val size: {len(val_pronounciations)}\\n\"\n",
    "    f\"Test size: {len(test_pronounciations)}\\n\"\n",
    ")\n",
    "\n",
    "for i in range(len(train_pronounciations)):\n",
    "    train_pronounciations[i] = \"@\" + train_pronounciations[i] + \"#\"\n",
    "\n",
    "for i in range(len(val_pronounciations)):\n",
    "    val_pronounciations[i] = \"@\" + val_pronounciations[i] + \"#\"\n",
    "\n",
    "for i in range(len(test_pronounciations)):\n",
    "    test_pronounciations[i] = \"@\" + test_pronounciations[i] + \"#\"\n",
    "\n",
    "ipa_tokenizer = Tokenizer(num_words = MAX_NUM_WORDS, filters = '')\n",
    "ipa_tokenizer.fit_on_texts(train_pronounciations)\n",
    "ipa_int_seq = ipa_tokenizer.texts_to_sequences(train_pronounciations)\n",
    "\n",
    "ipa_word_to_indx = ipa_tokenizer.word_index\n",
    "\n",
    "max_ipa_len = max(len(sen) for sen in ipa_int_seq)\n",
    "\n",
    "padded_tokenized_ipa = tf.keras.preprocessing.sequence.pad_sequences(ipa_int_seq, maxlen = max_ipa_len, padding = 'post', value = 0)\n",
    "\n",
    "padded_tokenized_ipa.shape\n",
    "\n",
    "print(len(ipa_tokenizer.index_word))\n",
    "print(ipa_tokenizer.word_index[\"@\"])\n",
    "\n",
    "\n",
    "val_tokenizer = Tokenizer(num_words = MAX_NUM_WORDS, filters = '')\n",
    "val_tokenizer.fit_on_texts(val_pronounciations)\n",
    "val_int_seq = val_tokenizer.texts_to_sequences(val_pronounciations)\n",
    "\n",
    "val_word_to_indx = val_tokenizer.word_index\n",
    "\n",
    "max_val_len = max(len(sen) for sen in val_int_seq)\n",
    "\n",
    "padded_tokenized_val = tf.keras.preprocessing.sequence.pad_sequences(val_int_seq, maxlen = max_val_len, padding = 'post', value = 0)\n",
    "\n",
    "padded_tokenized_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, None, 128), dtype=tf.float32, name=None), TensorSpec(shape=(None, 21), dtype=tf.int32, name=None))\n",
      "(TensorSpec(shape=(None, None, 128), dtype=tf.float32, name=None), TensorSpec(shape=(None, 19), dtype=tf.int32, name=None))\n",
      "(16, 13, 128)\n",
      "tf.Tensor(\n",
      "[[ 1  5  4 33  3  5  8  3  9 13  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 10  9 24  4 15  3  5 13  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 16 15 19  5 12 21  9  3 32 12  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  6  3  5 16  8  6  5 12  3  9  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 16 10  8  6  4  5 12  3  5 13  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 23 26 20  6 26 20 10 21 14 12  4 22  2  0  0  0  0  0  0  0]\n",
      " [ 1 28  3 27  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 31 25  9  6  8  4 22  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 14  5 26 20  6  5 17 10  6  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  4 22 10 34 30 19 18  4  6  3  5 13  2  0  0  0  0  0  0  0]\n",
      " [ 1 14 16 13  3  7  6  8  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 16 15 19 21  5 10  4 22  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 24  4 19 25  9  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 19  4 31  4  9 11  3  5 15  3  7  6  2  0  0  0  0  0  0  0]\n",
      " [ 1 33 12 36  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  8 10  5 17 14  8  2  0  0  0  0  0  0  0  0  0  0  0  0  0]], shape=(16, 21), dtype=int32)\n",
      "(16, 13, 128)\n",
      "tf.Tensor(\n",
      "[[ 1 10  4  6  3  5 13  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  5  4  8 12  6  8  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 15 21 14  6  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  6 21 30  3  9  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  3  7 10  3  5  5 22  4  6  3  5  2  0  0  0  0  0  0]\n",
      " [ 1 16 11  8  6 27  5  6  8  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  9 21  5 31  9 12  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  5  3 15  4 31 10  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  5 19 11  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 30 27  5 10 13  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 21 18 13  3  5 28 20  4 26  3  7 13  2  0  0  0  0  0]\n",
      " [ 1  8 11 20  4  9  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  8 11 16  5 12  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 24  5  3  6  3  5  7  3  6 12 13  2  0  0  0  0  0  0]\n",
      " [ 1  5 17  6  3 24 22  4  4 23  2  0  0  0  0  0  0  0  0]\n",
      " [ 1  9 12 10  3  5 13  2  0  0  0  0  0  0  0  0  0  0  0]], shape=(16, 19), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_words, padded_tokenized_ipa))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((val_words, padded_tokenized_val))\n",
    "\n",
    "def str_split(e, g):\n",
    "    e = tf.strings.split(e)\n",
    "    return e, g\n",
    " \n",
    "train_data = train_data.map(str_split)\n",
    "valid_data = valid_data.map(str_split)\n",
    "       \n",
    "embedding_layer = hub.load(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1\")    \n",
    "    \n",
    "def embed_english(x, y):\n",
    "    return embedding_layer(x), y\n",
    " \n",
    "train_data = train_data.map(embed_english)\n",
    "valid_data = valid_data.map(embed_english)\n",
    "\n",
    "\n",
    "def remove_long_sentence(e, g):\n",
    "    return tf.shape(e)[0] <= 13\n",
    " \n",
    "train_data = train_data.filter(remove_long_sentence)\n",
    "valid_data = valid_data.filter(remove_long_sentence)\n",
    "\n",
    "\n",
    "def pad_english(e, g):\n",
    "    return tf.pad(e, paddings = [[13-tf.shape(e)[0],0], [0,0]], mode='CONSTANT', constant_values=0), g\n",
    " \n",
    "train_data = train_data.map(pad_english)\n",
    "valid_data = valid_data.map(pad_english)\n",
    "\n",
    "train_data = train_data.batch(16)\n",
    "valid_data = valid_data.batch(16)\n",
    "\n",
    "print(train_data.element_spec)\n",
    "print(valid_data.element_spec)\n",
    "\n",
    "for e, g in train_data.take(1):\n",
    "    print(e.shape)\n",
    "    print(g)\n",
    " \n",
    "for e, g in valid_data.take(1):\n",
    "    print(e.shape)\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(Layer):\n",
    " \n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomLayer, self).__init__(**kwargs)\n",
    "        self.embed = tf.Variable(initial_value=tf.zeros(shape=(1,128)), trainable=True, dtype='float32')\n",
    "         \n",
    "    def call(self, inputs):\n",
    "        x = tf.tile(self.embed, [tf.shape(inputs)[0], 1])\n",
    "        x = tf.expand_dims(x, axis=1)\n",
    "        return tf.concat([inputs, x], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 13, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 14, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_layer = CustomLayer()\n",
    "e, g = next(iter(train_data.take(1)))\n",
    "print(e.shape)\n",
    "o = custom_layer(e)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 13, 128)]         0         \n",
      "                                                                 \n",
      " custom_layer (CustomLayer)  (None, 14, 128)           128       \n",
      "                                                                 \n",
      " masking_layer (Masking)     (None, 14, 128)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 512),             1312768   \n",
      "                              (None, 512),                       \n",
      "                              (None, 512)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,312,896\n",
      "Trainable params: 1,312,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(batch_shape = (None, 13, 128), name='input')\n",
    "x = CustomLayer(name='custom_layer')(inputs)\n",
    "x = Masking(mask_value=0, name='masking_layer')(x)\n",
    "x, h, c = LSTM(units=512, return_state=True, name='lstm')(x)\n",
    "encoder_model = Model(inputs = inputs, outputs = [h, c], name='encoder')\n",
    "\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer(train_words)\n",
    "#pronounciation_tokenizer = Tokenizer(train_pronounciations)\n",
    "#print(word_tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 21, 39) (16, 512) (16, 512)\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_layer (Embedding)  multiple                 4992      \n",
      "                                                                 \n",
      " lstm_layer (LSTM)           multiple                  1312768   \n",
      "                                                                 \n",
      " dense_layer (Dense)         multiple                  20007     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,337,767\n",
      "Trainable params: 1,337,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Decoder(Model):\n",
    "     \n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.embed = Embedding(input_dim=len(ipa_tokenizer.index_word)+1, output_dim=128, mask_zero=True, name='embedding_layer')\n",
    "        self.lstm = LSTM(units = 512, return_state = True, return_sequences = True, name='lstm_layer')\n",
    "        self.dense = Dense(len(ipa_tokenizer.index_word)+1, name='dense_layer')\n",
    "         \n",
    "    def call(self, inputs, hidden_state = None, cell_state = None):\n",
    "        x = self.embed(inputs)\n",
    "        x, hidden_state, cell_state = self.lstm(x, initial_state = [hidden_state, cell_state]) \\\n",
    "                                                     if hidden_state is not None and cell_state is not None else self.lstm(x)\n",
    "        x = self.dense(x)\n",
    "        return x, hidden_state, cell_state\n",
    " \n",
    "decoder_model = Decoder(name='decoder')\n",
    "e, g_in = next(iter(train_data.take(1)))\n",
    "h, c = encoder_model(e)\n",
    "g_out, h, c = decoder_model(g_in, h, c)\n",
    " \n",
    "print(g_out.shape, h.shape, c.shape)\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 1.1200305223464966, validation loss: 1.2953444719314575\n",
      "epoch: 1, train loss: 0.61591637134552, validation loss: 1.3291772603988647\n",
      "epoch: 2, train loss: 0.40657755732536316, validation loss: 1.3900686502456665\n",
      "epoch: 3, train loss: 0.31587252020835876, validation loss: 1.4802213907241821\n",
      "epoch: 4, train loss: 0.2671034634113312, validation loss: 1.5789763927459717\n",
      "epoch: 5, train loss: 0.23648999631404877, validation loss: 1.6962484121322632\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_ipa_decoder_data(g):\n",
    "    \n",
    "    g1 = g.numpy()\n",
    "    #print(g1)\n",
    "    #new_g1 =  np.delete(g1, np.where(g1 == 2), axis = 0)\n",
    "    '''\n",
    "    for list in g1:\n",
    "        for int in range(len(list)):\n",
    "            if list[int] == 2:\n",
    "                np.delete(list, [int])\n",
    "    '''\n",
    "    \n",
    "    x, y = g1.shape\n",
    "    #after delete\n",
    "    new_g1 = g1[g1 != 2]\n",
    "    new_g1 = np.reshape(new_g1, (x, y-1))\n",
    "\n",
    "    #print(new_g1)\n",
    "    \n",
    "    g2 = g.numpy()\n",
    "    new_g2 =  np.delete(g2,0, axis = 1)\n",
    "    new_g1 = np.pad(new_g1, ((0,0),(1,0)), 'constant')\n",
    "    g_in = tf.convert_to_tensor(new_g1, dtype=tf.int32)\n",
    "    \n",
    "    #print(g_in)\n",
    "    new_g2 = np.pad(new_g2, ((0,0),(0,1)), 'constant')\n",
    "    g_out = tf.convert_to_tensor(new_g2, dtype=tf.int32)\n",
    "    #print(g_out)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return g_in, g_out\n",
    "\n",
    "@tf.function\n",
    "def forward_backward(encoder_model, decoder_model, e, g_in, g_out, loss):\n",
    "    with tf.GradientTape() as tape:\n",
    "        h, c = encoder_model(e)\n",
    "        d_g_out, _, _ = decoder_model(g_in, h, c)\n",
    "        cur_loss = loss(g_out, d_g_out)\n",
    "        grads = tape.gradient(cur_loss, encoder_model.trainable_variables + decoder_model.trainable_variables)\n",
    "    return cur_loss, grads\n",
    " \n",
    "def train_encoder_decoder(encoder_model, decoder_model, num_epochs, train_data, valid_data, valid_steps, \n",
    "                          optimizer, loss, grad_fn):\n",
    "    train_losses = []\n",
    "    val_loasses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        val_epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        for e, g in train_data:\n",
    "            g_in, g_out = get_ipa_decoder_data(g)\n",
    "            #print(g_out)\n",
    "            #dropout = tf.keras.layers.Dropout(rate =0.75)\n",
    "            #g_out = dropout(g_out)\n",
    "            train_loss, grads = grad_fn(encoder_model, decoder_model, e, g_in, g_out, loss)\n",
    "            optimizer.apply_gradients(zip(grads, encoder_model.trainable_variables + decoder_model.trainable_variables))\n",
    "            train_epoch_loss_avg.update_state(train_loss)    \n",
    "        for e_v, g_v in valid_data.take(valid_steps):\n",
    "            g_v_in, g_v_out = get_ipa_decoder_data(g_v)\n",
    "            val_loss, _ = grad_fn(encoder_model, decoder_model, e_v, g_v_in, g_v_out, loss)\n",
    "            val_epoch_loss_avg.update_state(val_loss)        \n",
    "        print(f'epoch: {epoch}, train loss: {train_epoch_loss_avg.result()}, validation loss: {val_epoch_loss_avg.result()}')    \n",
    "        train_losses.append(train_epoch_loss_avg.result())\n",
    "        val_loasses.append(val_epoch_loss_avg.result())\n",
    "    return train_losses, val_loasses\n",
    " \n",
    "optimizer_obj = Adam(learning_rate = 1e-3)\n",
    "loss_obj = SparseCategoricalCrossentropy(from_logits=True)\n",
    "train_loss_results, valid_loss_results = train_encoder_decoder(encoder_model, decoder_model, 6, train_data, valid_data, 20,\n",
    "                                                          optimizer_obj, loss_obj, forward_backward)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xlabel(\"Epochs\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.title('Loss vs epochs')\n",
    "plt.plot(train_loss_results, label='train')\n",
    "plt.plot(valid_loss_results, label='valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 332  275 2305 3624 2073]\n",
      "TensorSpec(shape=(None, 128), dtype=tf.float32, name=None)\n",
      "tf.Tensor([[3]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[5]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[36]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[33]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[33]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[4]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[18]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[9]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "English Text:  w o r t h w h i l e \n",
      "IPA Transcription:  r θ h h ɪ e l UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s #\n",
      "\n",
      "tf.Tensor([[21]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[27]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[5]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[3]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[3]], shape=(1, 1), dtype=int64)\n",
      "English Text:  c o n v e r s e s \n",
      "IPA Transcription:  n v r s ə s ə #\n",
      "\n",
      "tf.Tensor([[4]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[4]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[25]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[11]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[5]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[4]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[11]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[5]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[11]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[11]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[19]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[11]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[11]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[19]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[29]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[29]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[20]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[30]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[4]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[4]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[30]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[26]], shape=(1, 1), dtype=int64)\n",
      "English Text:  d i s o r d e r e d \n",
      "IPA Transcription:  ɪ ɔ d r ɪ d r UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s d d b n d n d b n g g n ʊ u UNK s ɪ UNK s ɪ u o #\n",
      "\n",
      "tf.Tensor([[24]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[20]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[7]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[0]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[8]], shape=(1, 1), dtype=int64)\n",
      "English Text:  s o u n d n e s s \n",
      "IPA Transcription:  ʊ n n s s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s UNK s n UNK s n UNK s #\n",
      "\n",
      "tf.Tensor([[18]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[27]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[4]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[3]], shape=(1, 1), dtype=int64)\n",
      "tf.Tensor([[6]], shape=(1, 1), dtype=int64)\n",
      "English Text:  s a v a n t s \n",
      "IPA Transcription:  v ɪ ə t #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "english = test_words\n",
    "\n",
    "indices = np.random.choice(len(english), 5)\n",
    "\n",
    "print(indices)\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(np.array([english[i] for i in indices]))\n",
    "test_data = test_data.map(tf.strings.split)\n",
    "test_data = test_data.map(embedding_layer)\n",
    "test_data = test_data.filter(lambda x: tf.shape(x)[0] <= 13)\n",
    "test_data = test_data.map(lambda x: tf.pad(x, paddings = [[13-tf.shape(x)[0],0], [0,0]], mode='CONSTANT', constant_values=0))\n",
    "print(test_data.element_spec)\n",
    "# TensorSpec(shape=(None, 128), dtype=tf.float32, name=None)\n",
    "\n",
    "start_token = np.array(ipa_tokenizer.texts_to_sequences(['@']))\n",
    "end_token = np.array(ipa_tokenizer.texts_to_sequences(['#']))\n",
    "for e, i in zip(test_data.take(5), indices):\n",
    "\n",
    "    h, c = encoder_model(tf.expand_dims(e, axis=0))\n",
    "    g_t = []\n",
    "    g_in = start_token\n",
    "    g_out, h, c = decoder_model(g_in, h, c)\n",
    "    g_t.append('')\n",
    "    g_out = tf.argmax(g_out, axis=2)\n",
    "    while g_out != end_token: \n",
    "        #print(g_out)\n",
    "        g_out, h, c = decoder_model(g_in, h, c)\n",
    "        g_out = tf.argmax(g_out, axis=2)\n",
    "        g_in = g_out\n",
    "        g_t.append(ipa_tokenizer.index_word.get(tf.squeeze(g_out).numpy(), 'UNK'))\n",
    "    print(f'English Text: {english[i]}')\n",
    "    print(f'IPA Transcription: {\" \".join(g_t)}')\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3819268889.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [12]\u001b[1;36m\u001b[0m\n\u001b[1;33m    ipa =\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def bleu(model, tokenizer, sources, raw_dataset):\n",
    "    actual, predicted = [], []\n",
    "    for i, source in enumerate(sources):\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        ipa = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(Embedding(len(train_words), 512, input_length=20, mask_zero=True))\n",
    "#model.add(LSTM(512))\n",
    "#model.add(RepeatVector(20))\n",
    "#model.add(LSTM(512, return_sequences=True))\n",
    "#model.add(Dense(len(train_pronounciations), activation='softmax'))\n",
    " \n",
    "#rms = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "#model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a251302415591a00991e803008012c897957666279c59a7b2e49cbcc4b50ee2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
